{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from finance_byu.summarize import summary\n",
    "\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in the daily and monthly crsp datasets\n",
    "\n",
    "crsp_daily = pd.read_feather('~/FIN_585/crsp_data/crsp_daily.ftr')\n",
    "\n",
    "crsp_monthly = pd.read_feather('~/FIN_585/crsp_data/crsp_monthly.ftr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = pd.read_csv('~/FIN_585/crsp_data/ff.csv', parse_dates=['dateff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the daily dataset\n",
    "\n",
    "crsp_daily['prc'] = abs(crsp_daily['prc'])\n",
    "\n",
    "crsp_daily['prc_lag'] = crsp_daily.groupby('permno')['prc'].shift(1)\n",
    "\n",
    "crsp_daily = crsp_daily[crsp_daily['ret'] > -1]\n",
    "\n",
    "crsp_daily = crsp_daily[crsp_daily['prc_lag'] > 5]\n",
    "\n",
    "crsp_daily.sort_values(by = ['permno', 'caldt'], inplace = True)\n",
    "\n",
    "crsp_daily.drop(columns = ['shrcd', 'excd', 'siccd', 'vol', 'shr', 'prc_lag'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding column for positive and negative returns\n",
    "\n",
    "crsp_daily['ret_class'] = np.where(crsp_daily['ret'].shift(1) >= 0, '1', '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate rolling yearly number of positive and negative days for each stock\n",
    "\n",
    "n = 252\n",
    "\n",
    "crsp_daily['pos_days'] = crsp_daily.groupby('permno').rolling(window = n, min_periods = n)['ret_class'].sum().reset_index(level=0, drop=True)\n",
    "\n",
    "crsp_daily['neg_days'] = n - crsp_daily['pos_days']\n",
    "\n",
    "crsp_daily['%pos'] = crsp_daily['pos_days'] / n\n",
    "\n",
    "crsp_daily['%neg'] = crsp_daily['neg_days'] / n\n",
    "\n",
    "crsp_daily['%neg - %pos'] = crsp_daily['%neg'] - crsp_daily['%pos']\n",
    "\n",
    "crsp_daily.drop(columns = ['ret_class', 'pos_days', 'neg_days', '%pos', '%neg', 'prc', 'ret'], inplace = True)\n",
    "\n",
    "crsp_daily.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting daily data ready for merging with monthly data\n",
    "\n",
    "crsp_daily_resampled = crsp_daily.set_index('caldt').groupby('permno').resample('ME').first().droplevel('permno').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the monthly dataset\n",
    "\n",
    "crsp_monthly.drop(columns = ['shrcd', 'excd', 'siccd', 'vol', 'shr', 'cusip', 'ticker', 'prc', 'cumfacshr'], inplace = True)\n",
    "\n",
    "crsp_monthly.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the daily and monthly datasets\n",
    "\n",
    "merged_data = pd.merge(crsp_monthly, crsp_daily, on = ['permno', 'caldt'], how = 'inner')\n",
    "\n",
    "merged_data.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating momentum\n",
    "\n",
    "merged_data['log_ret'] = np.log(1 + merged_data['ret'])\n",
    "\n",
    "merged_data['cum_log_ret'] = merged_data.groupby('permno')['log_ret'].rolling(window = 11, min_periods = 11).sum().reset_index(drop=True)\n",
    "\n",
    "merged_data['momentum'] = merged_data.groupby('permno')['cum_log_ret'].shift(2)\n",
    "\n",
    "merged_data.drop(columns = ['log_ret', 'cum_log_ret'], inplace = True)\n",
    "\n",
    "merged_data.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate information discreatness 'id'\n",
    "\n",
    "merged_data['id'] = np.sign(merged_data['momentum']) * merged_data['%neg - %pos']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unconditional Sort (Sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unconditional double sort portfolios by momentum and id\n",
    "\n",
    "merged_data['momentum_bins'] = merged_data.groupby('caldt')['momentum'].transform(lambda x: pd.qcut(x, 2, labels = False))\n",
    "\n",
    "merged_data['id_bins'] = merged_data.groupby('caldt')['id'].transform(lambda x: pd.qcut(x, 5, labels = False))\n",
    "\n",
    "unconditional_port = merged_data.groupby(['caldt', 'momentum_bins', 'id_bins'])['ret'].mean().unstack(level=['momentum_bins', 'id_bins'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unconditional_port.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the unconditional double sort portfolio returns in-sample and out-of-sample\n",
    "\n",
    "unconditional_port_is = unconditional_port[(unconditional_port.index < '2008-01-01')]\n",
    "\n",
    "unconditional_port_oos = unconditional_port[unconditional_port.index >= '2008-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating differences in high and low momentum across id bins\n",
    "\n",
    "winner_losser_port_u = unconditional_port[1] - unconditional_port[0]\n",
    "\n",
    "winner_losser_port_u['spread'] = winner_losser_port_u[0] - winner_losser_port_u[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_losser_port_u = pd.merge(winner_losser_port_u, ff, left_on = 'caldt', right_on= 'dateff' ,how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the in-sample and out-of-sample information discreatness spread across momentum bins\n",
    "\n",
    "winner_losser_port_u_is = winner_losser_port_u[(winner_losser_port_u.dateff < '2008-01-01')]\n",
    "\n",
    "winner_losser_port_u_oos = winner_losser_port_u[winner_losser_port_u.dateff >= '2008-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate excess returns for all portfolios\n",
    "\n",
    "for i in range(0, 5):\n",
    "    winner_losser_port_u_is[f'excess_{i}'] = winner_losser_port_u_is[i] - winner_losser_port_u_is['rf']\n",
    "\n",
    "winner_losser_port_u_is['excess_spread'] = winner_losser_port_u_is['spread'] - winner_losser_port_u_is['rf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run regression to calculate the alpha and beta for the excess_0 to excess_4 & spread portfolios\n",
    "\n",
    "reg1 = ols('excess_0 ~ mktrf + smb + hml', data = winner_losser_port_u_is).fit()\n",
    "\n",
    "reg2 = ols('excess_1 ~ mktrf + smb + hml', data = winner_losser_port_u_is).fit()\n",
    "\n",
    "reg3 = ols('excess_2 ~ mktrf + smb + hml', data = winner_losser_port_u_is).fit()\n",
    "\n",
    "reg4 = ols('excess_3 ~ mktrf + smb + hml', data = winner_losser_port_u_is).fit()\n",
    "\n",
    "reg5 = ols('excess_4 ~ mktrf + smb + hml', data = winner_losser_port_u_is).fit()\n",
    "\n",
    "reg6 = ols('excess_spread ~ mktrf + smb + hml', data = winner_losser_port_u_is).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finance_byu.regtables import Regtable\n",
    "table = Regtable([reg1,reg2,reg3,reg4,reg5,reg6], stat='tstat', sig='coeff')\n",
    "table.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display((summary(unconditional_port_is)*100).round(2),\n",
    "        \n",
    "(summary(winner_losser_port_u_is[[0,1,2,3,4,'spread']])*100).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display((summary(unconditional_port_oos)*100).round(4),\n",
    "        \n",
    "(summary(winner_losser_port_u_oos[[0,1,2,3,4,'spread']])).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditional Sort (Independent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional double sort portfolios by momentum and id\n",
    "\n",
    "merged_data['conditional_id_bins'] = merged_data.groupby(['caldt', 'momentum_bins'])['id'].transform(lambda x: pd.qcut(x, 5, labels = False))\n",
    "\n",
    "conditional_port = merged_data.groupby(['caldt', 'momentum_bins', 'conditional_id_bins'])['ret'].mean().unstack(level=['momentum_bins', 'conditional_id_bins'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditional_port.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cqalculate the conditional double sort portfolio returns in-sample and out-of-sample\n",
    "\n",
    "conditional_port_is = conditional_port[(conditional_port.index < '2008-01-01') & (conditional_port.index >= '1980-01-01')]\n",
    "\n",
    "conditional_port_oos = conditional_port[(conditional_port.index >= '2008-01-01') & (conditional_port.index >= '1980-01-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating differences in high and low momentum across id bins\n",
    "\n",
    "winner_losser_port_c = conditional_port[1] - conditional_port[0]\n",
    "\n",
    "winner_losser_port_c['spread'] = winner_losser_port_c[0] - winner_losser_port_c[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_losser_port_c = pd.merge(winner_losser_port_c, ff, left_on = 'caldt', right_on= 'dateff' ,how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the in-sample and out-of-sample information discreatness spread across momentum bins\n",
    "\n",
    "winner_losser_port_c_is = winner_losser_port_c[(winner_losser_port_c.dateff < '2008-01-01') & (winner_losser_port_c.dateff >= '1980-01-01')]\n",
    "\n",
    "winner_losser_port_c_oos = winner_losser_port_c[(winner_losser_port_c.dateff >= '2008-01-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_losser_port_c_is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate excess returns for all portfolios\n",
    "\n",
    "for i in range(0, 5):\n",
    "    winner_losser_port_c_is[f'excess_{i}'] = winner_losser_port_c_is[i] - winner_losser_port_c_is['rf']\n",
    "\n",
    "winner_losser_port_c_is['excess_spread'] = winner_losser_port_c_is['spread'] - winner_losser_port_c_is['rf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_losser_port_c_is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run regression to calculate the alpha and beta for the excess_0 to excess_4 & spread portfolios\n",
    "\n",
    "reg1 = ols('excess_0 ~ mktrf + smb + hml', data = winner_losser_port_c_is).fit()\n",
    "\n",
    "reg2 = ols('excess_1 ~ mktrf + smb + hml', data = winner_losser_port_c_is).fit()\n",
    "\n",
    "reg3 = ols('excess_2 ~ mktrf + smb + hml', data = winner_losser_port_c_is).fit()\n",
    "\n",
    "reg4 = ols('excess_3 ~ mktrf + smb + hml', data = winner_losser_port_c_is).fit()\n",
    "\n",
    "reg5 = ols('excess_4 ~ mktrf + smb + hml', data = winner_losser_port_c_is).fit()\n",
    "\n",
    "reg6 = ols('excess_spread ~ mktrf + smb + hml', data = winner_losser_port_c_is).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finance_byu.regtables import Regtable\n",
    "table = Regtable([reg1,reg2,reg3,reg4,reg5,reg6], stat='tstat', sig='coeff')\n",
    "table.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display((summary(conditional_port_is)*100).round(4),\n",
    "        \n",
    "(summary(winner_losser_port_c_is[[0,1,2,3,4,'spread']])).round(4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
